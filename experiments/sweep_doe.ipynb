{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c303e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.integrate import solve_ivp\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.animation as animation\n",
    "from matplotlib.collections import LineCollection\n",
    "import matplotlib.colors as mcolors\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def setup_initial_conditions(N):\n",
    "    \n",
    "    \"\"\"    Set up the initial conditions for the FPU system.    \n",
    "    Args:        N (int): Number of particles in the FPU system.        \n",
    "    Returns:        y0 (np.ndarray): Initial state vector of size 2M, where M = N - 1.        \n",
    "    M (int): Number of interior particles (M = N - 1).    \n",
    "    \"\"\"\n",
    "    \n",
    "    M = N - 1\n",
    "    q0_full = np.zeros(M + 2)\n",
    "    p0_full = np.zeros(M + 2)\n",
    "    for k in range(1, M + 1):\n",
    "        q0_full[k] = math.sin(k * math.pi / N)\n",
    "    y0 = np.concatenate([q0_full[1:-1], p0_full[1:-1]])\n",
    "    return y0, M\n",
    "\n",
    "def acceleration(q_full, lambda_val):\n",
    "    linear = q_full[2:] - 2 * q_full[1:-1] + q_full[:-2]\n",
    "    nonlinear = lambda_val * ((q_full[2:] - q_full[1:-1])**2\n",
    "                             - (q_full[1:-1] - q_full[:-2])**2)\n",
    "    a = np.zeros_like(q_full)\n",
    "    a[1:-1] = linear + nonlinear\n",
    "    return a\n",
    "\n",
    "def rhs(t, y, M, lambda_val):\n",
    "    q_int = y[:M]\n",
    "    p_int = y[M:]\n",
    "    q_full = np.zeros(M + 2)\n",
    "    q_full[1:-1] = q_int\n",
    "    a_full = acceleration(q_full, lambda_val)\n",
    "    dqdt = p_int\n",
    "    dpdt = a_full[1:-1]\n",
    "    return np.concatenate([dqdt, dpdt])\n",
    "\n",
    "def precompute_modes(N, M):\n",
    "    sin_modes = [np.sin(l * np.arange(1, M+1) * math.pi / N) for l in range(1, M+1)]\n",
    "    omega_modes = [2 * math.sin(l * math.pi / (2 * N)) for l in range(1, M+1)]\n",
    "    return sin_modes, omega_modes\n",
    "\n",
    "def mode_energy(q_int, p_int, sinL, omega_L, N):\n",
    "    A_L   = math.sqrt(2/N) * np.dot(q_int, sinL)\n",
    "    A_dot = math.sqrt(2/N) * np.dot(p_int, sinL)\n",
    "    return 0.5*(A_dot**2 + (omega_L**2)*(A_L**2))\n",
    "\n",
    "def run_simulation(N=3, lambda_val=0.25, dt=0.1, T_end=3000.0, num_modes_to_plot=3):\n",
    "    y0, M = setup_initial_conditions(N)\n",
    "    steps = int(T_end / dt)\n",
    "    times = np.linspace(0, T_end, steps + 1)\n",
    "\n",
    "    # Solve ODE\n",
    "    sol = solve_ivp(rhs,\n",
    "                    t_span=(0, T_end),\n",
    "                    y0=y0,\n",
    "                    args=(M, lambda_val),\n",
    "                    method='RK45',\n",
    "                    t_eval=times,\n",
    "                    atol=1e-9,\n",
    "                    rtol=1e-9)\n",
    "\n",
    "    sin_modes, omega_modes = precompute_modes(N, M)\n",
    "\n",
    "    q_ts = sol.y[:M, :]\n",
    "    p_ts = sol.y[M:, :]\n",
    "\n",
    "    # Limit modes for plotting/energy computation\n",
    "    num_modes_to_plot = min(num_modes_to_plot, M)\n",
    "\n",
    "    energies = np.zeros((len(sol.t), num_modes_to_plot))\n",
    "    for idx in range(len(sol.t)):\n",
    "        qi = q_ts[:, idx]\n",
    "        pi = p_ts[:, idx]\n",
    "        for ell in range(num_modes_to_plot):\n",
    "            energies[idx, ell] = mode_energy(qi, pi, sin_modes[ell], omega_modes[ell], N)\n",
    "\n",
    "    # Build DataFrame for states\n",
    "    state_labels = [f'q_{i}' for i in range(1, M+1)] + [f'p_{i}' for i in range(1, M+1)]\n",
    "    trajectory = sol.y.T\n",
    "    df_fpu_states = pd.DataFrame(trajectory, columns=state_labels, index=sol.t)\n",
    "\n",
    "    return sol, df_fpu_states, energies, num_modes_to_plot\n",
    "\n",
    "def plot_modal_energies(sol, energies, num_modes_to_plot):\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    for ell in range(num_modes_to_plot):\n",
    "        plt.plot(sol.t, energies[:, ell], label=f'Mode {ell+1}')\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('Energy')\n",
    "    plt.title(f'Modal Energies for Modes 1–{num_modes_to_plot} (t up to {sol.t[-1]:.0f})')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plot_state_time_series(df_states, num_states_to_plot=3, max_points=1000):\n",
    "    max_states = min(num_states_to_plot, len(df_states.columns)//2)\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    time_vals = df_states.index.values[:max_points]\n",
    "    for i in range(max_states):\n",
    "        q_vals = df_states[f'q_{i+1}'].values[:max_points]\n",
    "        p_vals = df_states[f'p_{i+1}'].values[:max_points]\n",
    "        plt.plot(time_vals, q_vals, label=f'q_{i+1}')\n",
    "        plt.plot(time_vals, p_vals, '--', label=f'p_{i+1}')\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('State Value')\n",
    "    plt.title(f'FPU System State Time Series (First {max_states} Particles)')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    " \n",
    "def plot_phase_portrait (df_fpu_states, times):\n",
    "    # Plot phase space trajectory for the first particle\n",
    "    if times.shape[0] > len(df_fpu_states):\n",
    "        times = times[:len(df_fpu_states)]\n",
    "    if 'q_1' not in df_fpu_states or 'p_1' not in df_fpu_states:\n",
    "        raise ValueError(\"DataFrame must contain 'q_1' and 'p_1' columns for phase space plot.\")\n",
    "    if len(df_fpu_states) < times.shape[0]:\n",
    "        raise ValueError(\"DataFrame has fewer rows than the number of time points provided.\")\n",
    "  \n",
    "    plt.figure(figsize=(6, 5))\n",
    "    plt.plot(df_fpu_states['q_1'][:times.shape[0]], df_fpu_states['p_1'][:times.shape[0]], lw=0.1)\n",
    "    plt.xlabel('q_1')\n",
    "    plt.ylabel('p_1')\n",
    "    plt.title('Phase Space Trajectory for Particle 1')\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()    \n",
    "    \n",
    "\n",
    "def plot_phase_matrix(df_fpu_states, times=None, max_points=1000):\n",
    "    \"\"\"\n",
    "    Plot a matrix of phase portraits (q_i vs p_j) for the FPU system.\n",
    "\n",
    "    Args:\n",
    "        df_fpu_states: DataFrame with columns q_1,...,q_M, p_1,...,p_M\n",
    "        times: (optional) time array to determine length; if None, uses DataFrame length\n",
    "        max_points: maximum number of time steps to plot\n",
    "    \"\"\"\n",
    "    # --- helpers: sort columns by their numeric suffix ---\n",
    "    def sort_by_suffix(cols, prefix):\n",
    "        pairs = []\n",
    "        for c in cols:\n",
    "            m = re.match(fr\"{prefix}_(\\d+)$\", c)\n",
    "            if m:\n",
    "                pairs.append((int(m.group(1)), c))\n",
    "        return [c for _, c in sorted(pairs)]\n",
    "\n",
    "    q_cols = sort_by_suffix([c for c in df_fpu_states.columns if c.startswith('q_')], 'q')\n",
    "    p_cols = sort_by_suffix([c for c in df_fpu_states.columns if c.startswith('p_')], 'p')\n",
    "    n = min(len(q_cols), len(p_cols))\n",
    "\n",
    "    # time window\n",
    "    T = times.shape[0] if times is not None else len(df_fpu_states)\n",
    "    T = min(T, max_points)\n",
    "\n",
    "    fig, axes = plt.subplots(n, n, figsize=(3*n, 3*n), sharex=False, sharey=False)\n",
    "    if n == 1:\n",
    "        axes = axes.reshape(1, 1)\n",
    "\n",
    "    for i, q_col in enumerate(q_cols[:n]):\n",
    "        for j, p_col in enumerate(p_cols[:n]):\n",
    "            ax = axes[i, j]\n",
    "            if j < i:\n",
    "                ax.axis('off')\n",
    "                continue\n",
    "            ax.plot(df_fpu_states[q_col][:T], df_fpu_states[p_col][:T], lw=0.3)\n",
    "            ax.grid(True)\n",
    "            ax.set_xticks([])\n",
    "            ax.set_yticks([])\n",
    "            for spine in ax.spines.values():\n",
    "                spine.set_visible(True)\n",
    "\n",
    "    # Outer matrix labels\n",
    "    for j, p_col in enumerate(p_cols[:n]):\n",
    "        bbox = axes[0, j].get_position()\n",
    "        fig.text(bbox.x0 + bbox.width/2, bbox.y1 + 0.01, p_col, ha='center', va='bottom')\n",
    "    for i, q_col in enumerate(q_cols[:n]):\n",
    "        bbox = axes[i, 0].get_position()\n",
    "        fig.text(bbox.x0 - 0.01, bbox.y0 + bbox.height/2, q_col, ha='right', va='center', rotation=90)\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "def plot_phase_space_3d(df_states):\n",
    "    \"\"\"\n",
    "    Plot the 3D phase space trajectory using the first three states (q_1, q_2, q_3).\n",
    "    \"\"\"\n",
    "\n",
    "    if not all(f'q_{i}' in df_states.columns for i in range(1, 4)):\n",
    "        raise ValueError(\"DataFrame must contain 'q_1', 'q_2', and 'q_3' columns.\")\n",
    "\n",
    "    fig = plt.figure(figsize=(8, 6))\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    ax.plot(df_states['q_1'], df_states['q_2'], df_states['q_3'], lw=0.7)\n",
    "    ax.set_xlabel('q_1')\n",
    "    ax.set_ylabel('q_2')\n",
    "    ax.set_zlabel('q_3')\n",
    "    ax.set_title('3D Phase Space Trajectory (q_1, q_2, q_3)')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "def plot_hamiltonian_slice_only(df_fpu_states, N, lam, q_idx=0, p_idx=0, n=121):\n",
    "    \"\"\"\n",
    "    Plot true Hamiltonian on a 2D slice (q_idx, p_idx).\n",
    "    q_idx, p_idx: indices (0-based) of q and p to vary (others fixed at mean).\n",
    "    \"\"\"\n",
    "    Z = df_fpu_states.values.astype(np.float32)\n",
    "    anchor = Z.mean(axis=0)\n",
    "    M = Z.shape[1] // 2\n",
    "\n",
    "    # grid ranges (use percentiles for a nice view)\n",
    "    q_min, q_max = np.percentile(Z[:, q_idx], [0, 100])\n",
    "    p_min, p_max = np.percentile(Z[:, M + p_idx], [0, 100])\n",
    "\n",
    "    q_lin = np.linspace(q_min, q_max, n)\n",
    "    p_lin = np.linspace(p_min, p_max, n)\n",
    "    Q, P = np.meshgrid(q_lin, p_lin, indexing=\"xy\")\n",
    "\n",
    "    grid = np.tile(anchor, (n*n, 1))\n",
    "    grid[:, q_idx] = Q.ravel()\n",
    "    grid[:, M + p_idx] = P.ravel()\n",
    "\n",
    "    # helpers\n",
    "    def true_energy_np(z, N, lam):\n",
    "        z = np.atleast_2d(z)\n",
    "        M = z.shape[1] // 2\n",
    "        q, p = z[:, :M], z[:, M:]\n",
    "        KE = 0.5 * np.sum(p**2, axis=1)\n",
    "        qfull = np.zeros((z.shape[0], M+2))\n",
    "        qfull[:, 1:-1] = q\n",
    "        dq = qfull[:, 1:] - qfull[:, :-1]\n",
    "        PE = np.sum(0.5 * dq**2 + lam * dq**3 / 3.0, axis=1)\n",
    "        return KE + PE\n",
    "\n",
    "    H_vals = true_energy_np(grid, N=N, lam=lam).reshape(n, n)\n",
    "\n",
    "    # plot\n",
    "    fig, ax = plt.subplots(figsize=(7,5))\n",
    "    cs = ax.contourf(Q, P, H_vals, levels=60, alpha=0.5, cmap='inferno')\n",
    "    ax.set_title(f\"True Hamiltonian $H(q_{{{q_idx+1}}},p_{{{p_idx+1}}})$\")\n",
    "    ax.set_xlabel(f\"$q_{{{q_idx+1}}}$\")\n",
    "    ax.set_ylabel(f\"$p_{{{p_idx+1}}}$\")\n",
    "    cbar = fig.colorbar(cs, ax=ax)\n",
    "    cbar.set_label(\"H\")\n",
    "\n",
    "    # overlay the trajectory projection\n",
    "    q_traj = Z[:, q_idx]\n",
    "    p_traj = Z[:, M + p_idx]\n",
    "    ax.plot(q_traj, p_traj, c='w', lw=0.1, alpha=0.9, label=\"trajectory\")\n",
    "    ax.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()    \n",
    "    \n",
    "\n",
    "\n",
    "def animate_instantaneous_contours(df_fpu_states, N, lam,\n",
    "                                   i=1,              # 1..M (interior index)\n",
    "                                   stride=1,        # subsample frames\n",
    "                                   n=181,            # grid resolution\n",
    "                                   K_frames=None,    # cap frames after striding\n",
    "                                   interval=60,      # ms/frame\n",
    "                                   save_path=None,   # \"movie.mp4\" or \".gif\"\n",
    "                                   # shaded instantaneous field options\n",
    "                                   levels_bg=30,     # number of filled levels\n",
    "                                   cmap_bg='inferno',\n",
    "                                   field_alpha=0.6,\n",
    "                                   # fading tail (recent) options\n",
    "                                   tail_len=200,     # recent points to show (in framed steps)\n",
    "                                   tail_alpha_min=0.05,\n",
    "                                   tail_lw=1.4,\n",
    "                                   # NEW: permanent elapsed trail options\n",
    "                                   show_elapsed_trail=True,\n",
    "                                   elapsed_color='white',\n",
    "                                   elapsed_alpha=0.35,\n",
    "                                   elapsed_lw=0.5):\n",
    "    \"\"\"\n",
    "    Animate the (q_i,p_i) slice with:\n",
    "      - shaded instantaneous H_slice (contourf per frame)\n",
    "      - bold instantaneous energy level line\n",
    "      - red fading tail (recent points)\n",
    "      - red current point\n",
    "      - NEW: permanent white trail (history up to current time t), lw=0.5 by default\n",
    "    \"\"\"\n",
    "\n",
    "    Z = df_fpu_states.values.astype(np.float64)\n",
    "    M = Z.shape[1] // 2\n",
    "    assert 1 <= i <= M, f\"i must be in 1..{M}\"\n",
    "    qi = i - 1\n",
    "    pi = qi + M\n",
    "\n",
    "    q = Z[:, :M]\n",
    "    p = Z[:, M:]\n",
    "    T = Z.shape[0]\n",
    "\n",
    "    # neighbors (fixed ends → 0)\n",
    "    q_prev_t = np.zeros(T) if qi - 1 < 0 else q[:, qi - 1]\n",
    "    q_next_t = np.zeros(T) if qi + 1 > M - 1 else q[:, qi + 1]\n",
    "\n",
    "    # total energy H(t)\n",
    "    qfull = np.zeros((T, M + 2))\n",
    "    qfull[:, 1:-1] = q\n",
    "    dq = qfull[:, 1:] - qfull[:, :-1]\n",
    "    KE = 0.5 * np.sum(p**2, axis=1)\n",
    "    PE = np.sum(0.5 * dq**2 + lam * dq**3 / 3.0, axis=1)\n",
    "    H_total = KE + PE\n",
    "\n",
    "    # grid on (q_i, p_i)\n",
    "    qmin, qmax = np.percentile(q[:, qi], [1, 99])\n",
    "    pmin, pmax = np.percentile(p[:, qi], [1, 99])\n",
    "    pad_q = 0.05 * (qmax - qmin + 1e-12)\n",
    "    pad_p = 0.05 * (pmax - pmin + 1e-12)\n",
    "    qmin, qmax = qmin - pad_q, qmax + pad_q\n",
    "    pmin, pmax = pmin - pad_p, pmax + pad_p\n",
    "\n",
    "    q_lin = np.linspace(qmin, qmax, n)\n",
    "    p_lin = np.linspace(pmin, pmax, n)\n",
    "    Q, P = np.meshgrid(q_lin, p_lin, indexing=\"xy\")\n",
    "\n",
    "    # helpers to build H_slice\n",
    "    def H_slice_given_neighbors(q_prev, q_next, const):\n",
    "        dqL = Q - q_prev\n",
    "        dqR = q_next - Q\n",
    "        pot = 0.5 * (dqL**2 + dqR**2) + lam * (dqL**3 + dqR**3) / 3.0\n",
    "        return const + 0.5 * (P**2) + pot\n",
    "\n",
    "    def instantaneous_H_slice_at_t(t):\n",
    "        qi_now = q[t, qi]\n",
    "        pi_now = p[t, qi]\n",
    "        dqL_now = qi_now - q_prev_t[t]\n",
    "        dqR_now = q_next_t[t] - qi_now\n",
    "        pot_i_now = 0.5 * (dqL_now**2 + dqR_now**2) + lam * (dqL_now**3 + dqR_now**3) / 3.0\n",
    "        const = H_total[t] - (0.5 * pi_now**2 + pot_i_now)\n",
    "        return H_slice_given_neighbors(q_prev_t[t], q_next_t[t], const)\n",
    "\n",
    "    # frame indices\n",
    "    stride = max(1, int(stride))\n",
    "    idx = np.arange(0, T, stride)\n",
    "    if K_frames is not None:\n",
    "        idx = idx[:int(K_frames)]\n",
    "    if len(idx) == 0:\n",
    "        idx = np.array([0])\n",
    "\n",
    "    # figure & artists\n",
    "    fig, ax = plt.subplots(figsize=(8.8, 5.8))\n",
    "    ax.set_xlabel(f\"$q_{i}$\"); ax.set_ylabel(f\"$p_{i}$\")\n",
    "    ax.set_xlim(qmin, qmax);   ax.set_ylim(pmin, pmax)\n",
    "    ax.set_title(f\"(q{i}, p{i}) instantaneous energy level\")\n",
    "\n",
    "    # shaded instantaneous field (contourf) + bold energy level (contour)\n",
    "    cs_fill = [None]\n",
    "    cs_line = [None]\n",
    "    cbar    = [None]\n",
    "\n",
    "    def clear_fill():\n",
    "        if cs_fill[0] is not None:\n",
    "            for coll in cs_fill[0].collections:\n",
    "                coll.remove()\n",
    "            cs_fill[0] = None\n",
    "\n",
    "    def clear_line():\n",
    "        if cs_line[0] is not None:\n",
    "            for coll in cs_line[0].collections:\n",
    "                coll.remove()\n",
    "            cs_line[0] = None\n",
    "\n",
    "    # NEW: permanent elapsed trail line (white, low alpha)\n",
    "    if show_elapsed_trail:\n",
    "        elapsed_line, = ax.plot([], [], color=elapsed_color, alpha=elapsed_alpha,\n",
    "                                lw=elapsed_lw, zorder=2)\n",
    "    else:\n",
    "        elapsed_line = None\n",
    "\n",
    "    # red fading tail as LineCollection (recent history)\n",
    "    tail_coll = LineCollection([], linewidths=tail_lw, zorder=3)\n",
    "    ax.add_collection(tail_coll)\n",
    "\n",
    "    # red current point\n",
    "    point, = ax.plot([], [], \"o\", ms=5, color=\"white\", zorder=4)\n",
    "\n",
    "    # legend\n",
    "    legend_items = [point, tail_coll]\n",
    "    # legend_labels = [\"current\", \"recent tail\"]\n",
    "    legend_labels = [\"current state\"]\n",
    "    if show_elapsed_trail:\n",
    "        legend_items.insert(0, elapsed_line)\n",
    "        legend_labels.insert(0, \"elapsed trajetory\")\n",
    "    ax.legend(legend_items, legend_labels, framealpha=0.3, loc=\"upper right\")\n",
    "\n",
    "    def init():\n",
    "        clear_fill(); clear_line()\n",
    "        if cbar[0] is not None:\n",
    "            pass\n",
    "        tail_coll.set_segments([]); tail_coll.set_color([])\n",
    "        point.set_data([], [])\n",
    "        if elapsed_line is not None:\n",
    "            elapsed_line.set_data([], [])\n",
    "        return tail_coll, point if elapsed_line is None else (elapsed_line, tail_coll, point)\n",
    "\n",
    "    def update(k):\n",
    "        t = idx[k]\n",
    "\n",
    "        # shaded instantaneous field\n",
    "        H_slice = instantaneous_H_slice_at_t(t)\n",
    "        clear_fill()\n",
    "        cs_fill[0] = ax.contourf(Q, P, H_slice, levels=levels_bg,\n",
    "                                 cmap=cmap_bg,alpha=field_alpha, antialiased=True, zorder=0)\n",
    "        if cbar[0] is None:\n",
    "            cbar[0] = fig.colorbar(cs_fill[0], ax=ax)\n",
    "            cbar[0].set_label(\"H\")\n",
    "        else:\n",
    "            cbar[0].update_normal(cs_fill[0])\n",
    "        \n",
    "\n",
    "        # bold instantaneous energy level\n",
    "        vmin, vmax = float(np.nanmin(H_slice)), float(np.nanmax(H_slice))\n",
    "        level = float(np.clip(H_total[t], vmin + 1e-12, vmax - 1e-12))\n",
    "        clear_line()\n",
    "        \n",
    "        # map the scalar `level` to RGBA using the contourf's norm & cmap\n",
    "        norm = cs_fill[0].norm\n",
    "        cmap = cs_fill[0].cmap\n",
    "        rgba = list(cmap(norm(level)))\n",
    "        rgba[-1] = 1.0  # make the line fully opaque\n",
    "\n",
    "        cs_line[0] = ax.contour(Q, P, H_slice,\n",
    "                                levels=[level],\n",
    "                                colors=[tuple(rgba)],\n",
    "                                linewidths=0.9,\n",
    "                                zorder=1)  # keep above shading/tails   \n",
    "        \n",
    "        # Uncomment to use black contour line instead of colored\n",
    "        # cs_line[0] = ax.contour(Q, P, H_slice, levels=[level],\n",
    "        #                         colors=\"k\", linewidths=1.2, zorder=1)\n",
    "\n",
    "        # NEW: permanent elapsed trail up to current t (white, low alpha)\n",
    "        if elapsed_line is not None:\n",
    "            elapsed_line.set_data(q[:t+1, qi], p[:t+1, qi])\n",
    "\n",
    "        # red fading tail over last `tail_len` frames (post-stride)\n",
    "        t0 = max(0, t - tail_len)\n",
    "        x_tail = q[t0:t+1, qi]\n",
    "        y_tail = p[t0:t+1, qi]\n",
    "        if len(x_tail) >= 2:\n",
    "            segs = np.stack(\n",
    "                [np.column_stack([x_tail[:-1], y_tail[:-1]]),\n",
    "                 np.column_stack([x_tail[1:],  y_tail[1:]])],\n",
    "                axis=1\n",
    "            )\n",
    "            m = segs.shape[0]\n",
    "            alphas = np.linspace(tail_alpha_min, 1.0, m)\n",
    "            red = mcolors.to_rgb('white')\n",
    "            colors = [(*red, a) for a in alphas]\n",
    "            tail_coll.set_segments(segs)\n",
    "            tail_coll.set_color(colors)\n",
    "        else:\n",
    "            tail_coll.set_segments([]); tail_coll.set_color([])\n",
    "\n",
    "        # current point\n",
    "        point.set_data([q[t, qi]], [p[t, qi]])\n",
    "\n",
    "        ax.set_title(f\"(q{i}, p{i}) instantaneous energy level | t={t}\")\n",
    "        # Return artists (blit=False)\n",
    "        artists = [*cs_fill[0].collections, *cs_line[0].collections, tail_coll, point]\n",
    "        if elapsed_line is not None:\n",
    "            artists.insert(0, elapsed_line)\n",
    "        return artists\n",
    "\n",
    "    ani = animation.FuncAnimation(fig, update, init_func=init,\n",
    "                                  frames=len(idx), interval=interval, blit=False)\n",
    "\n",
    "    if save_path is not None:\n",
    "        ani.save(save_path, dpi=120)  # needs pillow (gif) or ffmpeg (mp4)\n",
    "        print(f\"Saved animation to {save_path}\")\n",
    "\n",
    "    plt.show()\n",
    "    return ani\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    N = 10\n",
    "    lambda_value = 0.25\n",
    "    sol, df_states, energies, num_modes = run_simulation(N=N, T_end=3000.0, lambda_val=lambda_value, num_modes_to_plot=10)\n",
    "    plot_modal_energies(sol, energies, num_modes)\n",
    "    plot_state_time_series(df_states, num_states_to_plot=10, max_points=1000)\n",
    "    plot_phase_portrait(df_states, sol.t)\n",
    "    # plot_phase_matrix(df_states, sol.t, max_points=100)\n",
    "    plot_hamiltonian_slice_only(df_states, N=N, lam=lambda_value, q_idx=0, p_idx=0 , n=121)\n",
    "\n",
    "    # animate_instantaneous_contours(\n",
    "    # df_states, N=N, lam=lambda_value,\n",
    "    # i=1, stride=1, n=181, K_frames=800,\n",
    "    # levels_bg=30, cmap_bg='inferno', field_alpha=0.65,\n",
    "    # tail_len=300, tail_alpha_min=0.06, tail_lw=1.4,\n",
    "    # show_elapsed_trail=True,      # <- permanent trail on\n",
    "    # elapsed_color='white',        # <- white\n",
    "    # elapsed_alpha=0.35,           # <- translucent\n",
    "    # elapsed_lw=0.5,               # <- line weight 0.5\n",
    "    # save_path=f'hamiltonian_contours_n={N}.gif'\n",
    "# )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "211da40d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================\n",
    "# HYPERPARAMETER SWEEP: SYMPNET vs LSTM on FPU\n",
    "# ==============================\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# --------- reproducibility ----------\n",
    "def set_seed(seed=123):\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "set_seed(123)\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# --------- data (from your simulation) ----------\n",
    "# expects df_fpu_states (T, 2M); N, lambda_value, dt already defined\n",
    "df_fpu_states = df_states  # from previous simulation\n",
    "Z_all = df_fpu_states.values.astype(np.float32)\n",
    "nf    = Z_all.shape[1]                   # = 2*M\n",
    "T     = len(Z_all)\n",
    "split = int(0.8 * T)                     # chronological split\n",
    "\n",
    "# One-step pairs (for SympNet)\n",
    "Z_tr  = Z_all[:split]\n",
    "Z_te  = Z_all[split:]\n",
    "Z_tr_in, Z_tr_out = Z_tr[:-1], Z_tr[1:]\n",
    "Z_te_in, Z_te_out = Z_te[:-1], Z_te[1:]\n",
    "\n",
    "train_ds_symp = TensorDataset(torch.from_numpy(Z_tr_in), torch.from_numpy(Z_tr_out))\n",
    "test_ds_symp  = TensorDataset(torch.from_numpy(Z_te_in), torch.from_numpy(Z_te_out))\n",
    "\n",
    "# Sequence data (for LSTM)\n",
    "def make_sequences(Z, seq_len=10):\n",
    "    X, Y = [], []\n",
    "    for i in range(len(Z) - seq_len):\n",
    "        X.append(Z[i:i+seq_len])\n",
    "        Y.append(Z[i+1:i+seq_len+1])\n",
    "    return np.asarray(X, np.float32), np.asarray(Y, np.float32)\n",
    "\n",
    "seq_len = 10\n",
    "X_tr, Y_tr = make_sequences(Z_tr, seq_len)\n",
    "X_te, Y_te = make_sequences(Z_te, seq_len)\n",
    "\n",
    "train_ds_lstm = TensorDataset(torch.from_numpy(X_tr), torch.from_numpy(Y_tr))\n",
    "test_ds_lstm  = TensorDataset(torch.from_numpy(X_te), torch.from_numpy(Y_te))\n",
    "\n",
    "# --------- Energy helper (true Hamiltonian) ----------\n",
    "def energy_np(z_batch, N, lam):\n",
    "    z = np.atleast_2d(z_batch)\n",
    "    M = z.shape[1] // 2\n",
    "    q, p = z[:, :M], z[:, M:]\n",
    "    KE = 0.5 * np.sum(p**2, axis=1)\n",
    "    qfull = np.zeros((z.shape[0], M+2), dtype=z.dtype)\n",
    "    qfull[:, 1:-1] = q\n",
    "    dq = qfull[:, 1:] - qfull[:, :-1]\n",
    "    PE = np.sum(0.5 * dq**2 + lam * dq**3 / 3.0, axis=1)\n",
    "    return KE + PE\n",
    "\n",
    "# ---------- SympNet (parametric) ----------\n",
    "\n",
    "class SymplecticNN_Generator(nn.Module):\n",
    "    def __init__(self, dim, width=64, num_hidden=3):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "        self.half = dim // 2\n",
    "        layers = []\n",
    "        in_dim = dim\n",
    "        for _ in range(num_hidden):\n",
    "            layers += [nn.Linear(in_dim, width), nn.Tanh()]\n",
    "            in_dim = width\n",
    "        layers += [nn.Linear(in_dim, 1)]\n",
    "        self.S = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, z, create_graph: bool = True):\n",
    "        z = z.requires_grad_(True)                    \n",
    "        S_val = self.S(z)                               \n",
    "        grads = torch.autograd.grad(\n",
    "            S_val.sum(), z, create_graph=create_graph)[0]                                           \n",
    "        dqdt = grads[:, self.half:]                     \n",
    "        dpdt = -grads[:, :self.half]                    \n",
    "        return torch.cat([dqdt, dpdt], dim=1)\n",
    "\n",
    "\n",
    "def symp_midpoint_step(model, z0, h, n_iter=5, create_graph=True):\n",
    "    z1 = z0.clone()\n",
    "    for _ in range(n_iter):\n",
    "        # IMPORTANT: allow grad recording here (even in eval)\n",
    "        with torch.enable_grad():\n",
    "            z_mid = 0.5 * (z0 + z1).detach().requires_grad_(True)\n",
    "            f_mid = model(z_mid, create_graph=create_graph)\n",
    "            z1 = z0 + h * f_mid\n",
    "    return z1\n",
    "\n",
    "\n",
    "mse = nn.MSELoss()\n",
    "dt = 0.1 \n",
    "\n",
    "def train_sympnet(dim, width, num_hidden, train_ds, test_ds, epochs=200, lr=1e-3, batch_size=256, h=dt):\n",
    "    model = SymplecticNN_Generator(dim, width=width, num_hidden=num_hidden).to(device).float()\n",
    "    opt   = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "    test_loader  = DataLoader(test_ds,  batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    # --- train ---\n",
    "    t0 = time.time()\n",
    "    for ep in range(epochs):\n",
    "        model.train()\n",
    "        running = 0.0\n",
    "        for x0, x1 in train_loader:\n",
    "            x0 = x0.to(device); x1 = x1.to(device)\n",
    "            opt.zero_grad()\n",
    "            x1_hat = symp_midpoint_step(model, x0, h, create_graph=True)\n",
    "            loss = mse(x1_hat, x1)\n",
    "\n",
    "            loss.backward(); opt.step()\n",
    "            running += loss.item() * x0.size(0)\n",
    "        train_mse = running / len(train_ds)\n",
    "\n",
    "    # --- eval on test (one-step MSE) ---\n",
    "    model.eval()\n",
    "    running_test = 0.0\n",
    "    for x0, x1 in test_loader:\n",
    "        x0 = x0.to(device); x1 = x1.to(device)\n",
    "        x1_hat = symp_midpoint_step(model, x0, h, create_graph=False)\n",
    "        running_test += mse(x1_hat, x1).item() * x0.size(0)\n",
    "    test_mse = running_test / len(test_ds)\n",
    "    \n",
    "\n",
    "    # --- energy drift on an autoregressive reconstruction (train horizon) ---\n",
    "    # autoregressive reconstruction over train horizon\n",
    "    Ztr = Z_tr.astype(np.float32)\n",
    "    z_t = torch.from_numpy(Ztr[:1]).to(device)\n",
    "    pred = np.zeros_like(Ztr)\n",
    "    for t in range(len(Ztr)):\n",
    "        pred[t] = z_t.squeeze(0).cpu().numpy()\n",
    "        z_t = symp_midpoint_step(model, z_t, h, create_graph=False)\n",
    "    H_pred = energy_np(pred, N, lambda_value)\n",
    "    dH = H_pred - H_pred[0]\n",
    "    drift_rms = float(np.sqrt(np.mean(dH**2)))\n",
    "    drift_max = float(np.max(np.abs(dH)))\n",
    "\n",
    "\n",
    "    n_params = sum(p.numel() for p in model.parameters())\n",
    "    secs = time.time() - t0\n",
    "    return model, dict(train_mse=train_mse, test_mse=test_mse,\n",
    "                       drift_rms=drift_rms, drift_max=drift_max,\n",
    "                       params=n_params, seconds=secs)\n",
    "\n",
    "# ---------- LSTM (parametric) ----------\n",
    "class FPU_LSTM(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim=64, num_layers=1):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers, batch_first=True)\n",
    "        self.fc   = nn.Linear(hidden_dim, input_dim)\n",
    "    def forward(self, x, hc=None):\n",
    "        # x: [B, L, D]\n",
    "        out, hc = self.lstm(x, hc)         # [B, L, H]\n",
    "        out = self.fc(out)                  # [B, L, D]\n",
    "        return out, hc\n",
    "\n",
    "def train_lstm(input_dim, hidden_dim, train_ds, test_ds,\n",
    "               epochs=20, lr=1e-3, batch_size=128):\n",
    "    model = FPU_LSTM(input_dim, hidden_dim=hidden_dim, num_layers=1).to(device).float()\n",
    "    opt   = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    lossf = nn.MSELoss()\n",
    "    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "    test_loader  = DataLoader(test_ds,  batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    t0 = time.time()\n",
    "    for ep in range(epochs):\n",
    "        model.train()\n",
    "        running = 0.0\n",
    "        for xb, yb in train_loader:\n",
    "            xb = xb.to(device); yb = yb.to(device)\n",
    "            opt.zero_grad()\n",
    "            out, _ = model(xb)\n",
    "            loss = lossf(out, yb)\n",
    "            loss.backward(); opt.step()\n",
    "            running += loss.item() * xb.size(0)\n",
    "        train_mse = running / len(train_ds)\n",
    "\n",
    "    # test mse (teacher-forced)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        running = 0.0\n",
    "        for xb, yb in test_loader:\n",
    "            xb = xb.to(device); yb = yb.to(device)\n",
    "            out, _ = model(xb)\n",
    "            running += lossf(out, yb).item() * xb.size(0)\n",
    "        test_mse = running / len(test_ds)\n",
    "\n",
    "    # energy drift on autoregressive rollout over the train horizon\n",
    "    with torch.no_grad():\n",
    "        # autoregressive 1-step using the LSTM cell with state carry\n",
    "        z_t = torch.from_numpy(Z_tr[:1]).to(device)      # [1, D]\n",
    "        hc  = None\n",
    "        pred = np.zeros_like(Z_tr)\n",
    "        for t in range(len(Z_tr)):\n",
    "            # feed as a length-1 sequence\n",
    "            out, hc = model(z_t.unsqueeze(1), hc)        # [1,1,D]\n",
    "            z_next = out[:, -1, :]\n",
    "            pred[t] = z_t.squeeze(0).cpu().numpy()       # store current\n",
    "            z_t = z_next.detach()                        # next input = last output\n",
    "        H_pred = energy_np(pred, N, lambda_value)\n",
    "        dH = H_pred - H_pred[0]\n",
    "        drift_rms = float(np.sqrt(np.mean(dH**2)))\n",
    "        drift_max = float(np.max(np.abs(dH)))\n",
    "\n",
    "    n_params = sum(p.numel() for p in model.parameters())\n",
    "    secs = time.time() - t0\n",
    "    return model, dict(train_mse=train_mse, test_mse=test_mse,\n",
    "                       drift_rms=drift_rms, drift_max=drift_max,\n",
    "                       params=n_params, seconds=secs)\n",
    "\n",
    "# ---------- sweep space ----------\n",
    "width_mults   = [1, 2, 4, 8]          # × nf\n",
    "hidden_layers = [1, 2, 4, 8]          # SympNet only\n",
    "\n",
    "# (tune these to your budget)\n",
    "EPOCHS_SYMP = 10     # e.g., 200–1000; higher = better but slower\n",
    "EPOCHS_LSTM = 10      # teacher-forced; 50–200 typical\n",
    "BATCH_SYMP  = 256\n",
    "BATCH_LSTM  = 128\n",
    "LR_SYMP     = 1e-3\n",
    "LR_LSTM     = 1e-3\n",
    "\n",
    "# ---------- run sweep ----------\n",
    "results = []\n",
    "\n",
    "# SympNet grid\n",
    "for L in hidden_layers:\n",
    "    for mult in width_mults:\n",
    "        width = mult * nf\n",
    "        model, metrics = train_sympnet(\n",
    "            dim=nf, width=width, num_hidden=L,\n",
    "            train_ds=train_ds_symp, test_ds=test_ds_symp,\n",
    "            epochs=EPOCHS_SYMP, lr=LR_SYMP, batch_size=BATCH_SYMP, h=float(dt)\n",
    "        )\n",
    "        row = dict(model='SympNet', layers=L, width=width, **metrics)\n",
    "        results.append(row)\n",
    "        print(f\"[SympNet] layers={L:>2}, width={width:>4} | \"\n",
    "              f\"train={metrics['train_mse']:.3e}  test={metrics['test_mse']:.3e}  \"\n",
    "              f\"drift_rms={metrics['drift_rms']:.3e}  params={metrics['params']}\")\n",
    "\n",
    "# LSTM grid\n",
    "for mult in width_mults:\n",
    "    hid = mult * nf\n",
    "    model, metrics = train_lstm(\n",
    "        input_dim=nf, hidden_dim=hid,\n",
    "        train_ds=train_ds_lstm, test_ds=test_ds_lstm,\n",
    "        epochs=EPOCHS_LSTM, lr=LR_LSTM, batch_size=BATCH_LSTM\n",
    "    )\n",
    "    row = dict(model='LSTM', layers=1, width=hid, **metrics)\n",
    "    results.append(row)\n",
    "    print(f\"[LSTM]    hidden={hid:>4} | \"\n",
    "          f\"train={metrics['train_mse']:.3e}  test={metrics['test_mse']:.3e}  \"\n",
    "          f\"drift_rms={metrics['drift_rms']:.3e}  params={metrics['params']}\")\n",
    "\n",
    "# ---------- collate & view ----------\n",
    "df_sweep = pd.DataFrame(results)\n",
    "df_sweep = df_sweep[['model','layers','width','params','train_mse','test_mse','drift_rms','drift_max','seconds']]\n",
    "display(df_sweep.sort_values(['model','test_mse']).reset_index(drop=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8d00ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# --- 1) Metric vs parameter count (one chart per metric) ---\n",
    "def plot_metric_vs_params(df, metric, title=None):\n",
    "    plt.figure(figsize=(7,5))\n",
    "    for name, g in df.groupby('model'):\n",
    "        g = g.sort_values('params')\n",
    "        plt.plot(g['params'].values, g[metric].values, 'o-', label=name)\n",
    "    plt.xscale('log'); plt.yscale('log')\n",
    "    plt.xlabel('# parameters'); plt.ylabel(metric)\n",
    "    if title: plt.title(title)\n",
    "    plt.grid(True, which='both', linestyle=':')\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_metric_vs_params(df_sweep, 'test_mse',  title='Test MSE vs #params')\n",
    "plot_metric_vs_params(df_sweep, 'train_mse', title='Reconstruction MSE vs #params')\n",
    "plot_metric_vs_params(df_sweep, 'drift_rms', title='Energy drift (RMS) vs #params')\n",
    "\n",
    "# --- 2) Pareto-style tradeoff: Test MSE vs Energy Drift (size ~ params) ---\n",
    "def plot_pareto(df, x='test_mse', y='drift_rms'):\n",
    "    plt.figure(figsize=(7,5))\n",
    "    for name, g in df.groupby('model'):\n",
    "        sizes = 30 * (np.log10(g['params'].values) - np.log10(df['params'].min()) + 1.0)\n",
    "        plt.scatter(g[x].values, g[y].values, s=sizes, alpha=0.8, label=name)\n",
    "    plt.xscale('log'); plt.yscale('log')\n",
    "    plt.xlabel(x); plt.ylabel(y)\n",
    "    plt.title('Tradeoff: Test MSE vs Energy Drift (marker size ~ #params)')\n",
    "    plt.grid(True, which='both', linestyle=':')\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_pareto(df_sweep)\n",
    "\n",
    "# --- 3) SympNet heatmaps: test MSE / drift across (layers × width_mult) ---\n",
    "# (width_mult = width / nf)\n",
    "symp = df_sweep[df_sweep['model']=='SympNet'].copy()\n",
    "symp['width_mult'] = (symp['width'] / float(nf)).round().astype(int)\n",
    "\n",
    "def heatmap_metric(symp_df, metric, title):\n",
    "    pt = symp_df.pivot_table(index='layers', columns='width_mult', values=metric, aggfunc='min')\n",
    "    layers_sorted = sorted(pt.index)\n",
    "    cols_sorted   = sorted(pt.columns)\n",
    "    pt = pt.loc[layers_sorted, cols_sorted]\n",
    "\n",
    "    plt.figure(figsize=(6,4.8))\n",
    "    im = plt.imshow(np.log10(pt.values), aspect='auto', origin='lower',\n",
    "                    extent=[min(cols_sorted)-0.5, max(cols_sorted)+0.5,\n",
    "                            min(layers_sorted)-0.5, max(layers_sorted)+0.5])\n",
    "    cbar = plt.colorbar(im)\n",
    "    cbar.set_label(f'log10({metric})')\n",
    "    plt.xticks(cols_sorted); plt.yticks(layers_sorted)\n",
    "    plt.xlabel('width_mult (× nf)'); plt.ylabel('hidden layers')\n",
    "    plt.title(title)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "if not symp.empty:\n",
    "    heatmap_metric(symp, 'test_mse',  'SympNet: test MSE across (layers × width_mult)')\n",
    "    heatmap_metric(symp, 'drift_rms', 'SympNet: drift RMS across (layers × width_mult)')\n",
    "\n",
    "# --- 4) Param-matched head-to-head (nearest #params LSTM for each SympNet row) ---\n",
    "def nearest_param_pairs(df):\n",
    "    symp = df[df.model=='SympNet'].copy()\n",
    "    lstm = df[df.model=='LSTM'].copy()\n",
    "    rows = []\n",
    "    for _, r in symp.iterrows():\n",
    "        j = (lstm['params'] - r['params']).abs().idxmin()\n",
    "        m = lstm.loc[j]\n",
    "        rows.append({\n",
    "            'symp_params': int(r['params']),\n",
    "            'lstm_params': int(m['params']),\n",
    "            'symp_layers': int(r['layers']),\n",
    "            'symp_width' : int(r['width']),\n",
    "            'lstm_width' : int(m['width']),\n",
    "            'symp_test_mse': r['test_mse'],\n",
    "            'lstm_test_mse': m['test_mse'],\n",
    "            'symp_drift_rms': r['drift_rms'],\n",
    "            'lstm_drift_rms': m['drift_rms'],\n",
    "        })\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "df_match = nearest_param_pairs(df_sweep)\n",
    "display(df_match.sort_values('symp_params').reset_index(drop=True))\n",
    "\n",
    "# Optional quick bar plots for matched pairs\n",
    "def bar_compare(df_match, metric, title):\n",
    "    x = np.arange(len(df_match))\n",
    "    width = 0.4\n",
    "    plt.figure(figsize=(8,4.5))\n",
    "    plt.bar(x - width/2, df_match[f'symp_{metric}'].values, width, label='SympNet')\n",
    "    plt.bar(x + width/2, df_match[f'lstm_{metric}'].values, width, label='LSTM')\n",
    "    plt.yscale('log')\n",
    "    plt.xticks(x, [f\"{p//1000}k\" for p in df_match['symp_params']], rotation=0)\n",
    "    plt.xlabel('~Matched parameter count (SympNet side)')\n",
    "    plt.ylabel(metric)\n",
    "    plt.title(title)\n",
    "    plt.grid(True, which='both', axis='y', linestyle=':')\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "if len(df_match):\n",
    "    bar_compare(df_match, 'test_mse',   'Param-matched: Test MSE (log scale)')\n",
    "    bar_compare(df_match, 'drift_rms',  'Param-matched: Energy drift RMS (log scale)')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3124646f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "mse = nn.MSELoss()\n",
    "\n",
    "# ----- data from your sim -----\n",
    "Z_all = df_fpu_states.values.astype(np.float32)   # [T, 2M]\n",
    "nf    = Z_all.shape[1]\n",
    "T     = len(Z_all)\n",
    "split = int(0.8 * T)\n",
    "\n",
    "# SympNet one-step pairs\n",
    "Z_tr  = Z_all[:split]\n",
    "Z_te  = Z_all[split:]\n",
    "Z_tr_in, Z_tr_out = Z_tr[:-1], Z_tr[1:]\n",
    "Z_te_in, Z_te_out = Z_te[:-1], Z_te[1:]\n",
    "train_ds_symp = TensorDataset(torch.from_numpy(Z_tr_in), torch.from_numpy(Z_tr_out))\n",
    "test_ds_symp  = TensorDataset(torch.from_numpy(Z_te_in), torch.from_numpy(Z_te_out))\n",
    "\n",
    "# LSTM sequences\n",
    "def make_sequences(Z, seq_len=10):\n",
    "    X, Y = [], []\n",
    "    for i in range(len(Z) - seq_len):\n",
    "        X.append(Z[i:i+seq_len]); Y.append(Z[i+1:i+seq_len+1])\n",
    "    return np.asarray(X, np.float32), np.asarray(Y, np.float32)\n",
    "\n",
    "seq_len = 10\n",
    "X_tr, Y_tr = make_sequences(Z_tr, seq_len)\n",
    "X_te, Y_te = make_sequences(Z_te, seq_len)\n",
    "train_ds_lstm = TensorDataset(torch.from_numpy(X_tr), torch.from_numpy(Y_tr))\n",
    "test_ds_lstm  = TensorDataset(torch.from_numpy(X_te), torch.from_numpy(Y_te))\n",
    "\n",
    "# ----- energy helper -----\n",
    "def energy_np(z_batch, N, lam):\n",
    "    z = np.atleast_2d(z_batch)\n",
    "    M = z.shape[1] // 2\n",
    "    q, p = z[:, :M], z[:, M:]\n",
    "    KE = 0.5 * np.sum(p**2, axis=1)\n",
    "    qfull = np.zeros((z.shape[0], M+2), dtype=z.dtype); qfull[:,1:-1] = q\n",
    "    dq = qfull[:,1:] - qfull[:,:-1]\n",
    "    PE = np.sum(0.5*dq**2 + lam*dq**3/3.0, axis=1)\n",
    "    return KE + PE\n",
    "\n",
    "# ----- SympNet model & step -----\n",
    "class SymplecticNN_Generator(nn.Module):\n",
    "    def __init__(self, dim, width=64, num_hidden=3):\n",
    "        super().__init__()\n",
    "        self.dim = dim; self.half = dim // 2\n",
    "        layers = []; d = dim\n",
    "        for _ in range(num_hidden):\n",
    "            layers += [nn.Linear(d, width), nn.Tanh()]; d = width\n",
    "        layers += [nn.Linear(d, 1)]\n",
    "        self.S = nn.Sequential(*layers)\n",
    "    def forward(self, z, create_graph=True):\n",
    "        z = z.requires_grad_(True)\n",
    "        S_val = self.S(z)\n",
    "        grads = torch.autograd.grad(S_val.sum(), z, create_graph=create_graph)[0]\n",
    "        dqdt = grads[:, self.half:]; dpdt = -grads[:, :self.half]\n",
    "        return torch.cat([dqdt, dpdt], dim=1)\n",
    "\n",
    "def symp_midpoint_step(model, z0, h, n_iter=5, create_graph=True):\n",
    "    z1 = z0.clone()\n",
    "    for _ in range(n_iter):\n",
    "        with torch.enable_grad():\n",
    "            z_mid = 0.5*(z0 + z1).detach().requires_grad_(True)\n",
    "            f_mid = model(z_mid, create_graph=create_graph)\n",
    "            z1 = z0 + h * f_mid\n",
    "    return z1\n",
    "\n",
    "# ----- LSTM model -----\n",
    "class FPU_LSTM(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim=64, num_layers=1):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers, batch_first=True)\n",
    "        self.fc   = nn.Linear(hidden_dim, input_dim)\n",
    "    def forward(self, x, hc=None):\n",
    "        out, hc = self.lstm(x, hc)\n",
    "        out = self.fc(out)\n",
    "        return out, hc\n",
    "\n",
    "# ----- drift evaluators (short horizon to keep it fast) -----\n",
    "def drift_rms_symp(model, Z_ref, N, lam, h, H=1000):\n",
    "    H = min(H, len(Z_ref))\n",
    "    z_t = torch.from_numpy(Z_ref[:1]).to(device)\n",
    "    pred = np.zeros((H, Z_ref.shape[1]), dtype=np.float32)\n",
    "    for t in range(H):\n",
    "        pred[t] = z_t.squeeze(0).cpu().numpy()\n",
    "        z_t = symp_midpoint_step(model, z_t, h, create_graph=False)\n",
    "    dH = energy_np(pred, N, lam) - energy_np(pred[:1], N, lam)[0]\n",
    "    return float(np.sqrt(np.mean(dH**2)))\n",
    "\n",
    "def drift_rms_lstm(model, Z_ref, H=1000):\n",
    "    H = min(H, len(Z_ref))\n",
    "    z_t = torch.from_numpy(Z_ref[:1]).to(device)\n",
    "    hc  = None\n",
    "    pred = np.zeros((H, Z_ref.shape[1]), dtype=np.float32)\n",
    "    for t in range(H):\n",
    "        pred[t] = z_t.squeeze(0).cpu().numpy()\n",
    "        out, hc = model(z_t.unsqueeze(1), hc)     # [1,1,D]\n",
    "        z_t = out[:, -1, :].detach()\n",
    "    # Use same FPU Hamiltonian as truth for drift metric\n",
    "    dH = energy_np(pred, N, lambda_value) - energy_np(pred[:1], N, lambda_value)[0]\n",
    "    return float(np.sqrt(np.mean(dH**2)))\n",
    "\n",
    "# ----- training with history -----\n",
    "def train_sympnet_with_history(dim, width, num_hidden, train_ds, test_ds,\n",
    "                               epochs=200, lr=1e-3, batch_size=256, h=dt,\n",
    "                               eval_every=5, drift_H=800):\n",
    "    model = SymplecticNN_Generator(dim, width=width, num_hidden=num_hidden).to(device).float()\n",
    "    opt   = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    tl = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "    vl = DataLoader(test_ds,  batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    hist = dict(train=[], test=[], drift=[])\n",
    "    for ep in range(epochs):\n",
    "        model.train()\n",
    "        run = 0.0\n",
    "        for x0, x1 in tl:\n",
    "            x0 = x0.to(device); x1 = x1.to(device)\n",
    "            opt.zero_grad()\n",
    "            x1_hat = symp_midpoint_step(model, x0, h, create_graph=True)\n",
    "            loss = mse(x1_hat, x1)\n",
    "            loss.backward(); opt.step()\n",
    "            run += loss.item() * x0.size(0)\n",
    "        train_mse = run / len(train_ds)\n",
    "        hist['train'].append(train_mse)\n",
    "\n",
    "        if (ep % eval_every == 0) or (ep == epochs-1):\n",
    "            model.eval()\n",
    "            # test MSE (needs grad enabled for ∇S, but no backprop graph)\n",
    "            test_run = 0.0\n",
    "            for x0, x1 in vl:\n",
    "                x0 = x0.to(device); x1 = x1.to(device)\n",
    "                x1_hat = symp_midpoint_step(model, x0, h, create_graph=False)\n",
    "                test_run += mse(x1_hat, x1).item() * x0.size(0)\n",
    "            test_mse = test_run / len(test_ds)\n",
    "            hist['test'].append((ep, test_mse))\n",
    "\n",
    "            # drift RMS on a short reconstruction\n",
    "            d_rms = drift_rms_symp(model, Z_tr.astype(np.float32), N, lambda_value, h, H=drift_H)\n",
    "            hist['drift'].append((ep, d_rms))\n",
    "    return model, hist\n",
    "\n",
    "def train_lstm_with_history(input_dim, hidden_dim, train_ds, test_ds,\n",
    "                            epochs=200, lr=1e-3, batch_size=128,\n",
    "                            eval_every=5, drift_H=800):\n",
    "    model = FPU_LSTM(input_dim, hidden_dim=hidden_dim, num_layers=1).to(device).float()\n",
    "    opt   = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    tl = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "    vl = DataLoader(test_ds,  batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    hist = dict(train=[], test=[], drift=[])\n",
    "    for ep in range(epochs):\n",
    "        model.train()\n",
    "        run = 0.0\n",
    "        for xb, yb in tl:\n",
    "            xb = xb.to(device); yb = yb.to(device)\n",
    "            opt.zero_grad()\n",
    "            out, _ = model(xb)\n",
    "            loss = mse(out, yb)\n",
    "            loss.backward(); opt.step()\n",
    "            run += loss.item() * xb.size(0)\n",
    "        train_mse = run / len(train_ds)\n",
    "        hist['train'].append(train_mse)\n",
    "\n",
    "        if (ep % eval_every == 0) or (ep == epochs-1):\n",
    "            model.eval()\n",
    "            test_run = 0.0\n",
    "            for xb, yb in vl:\n",
    "                xb = xb.to(device); yb = yb.to(device)\n",
    "                out, _ = model(xb)\n",
    "                test_run += mse(out, yb).item() * xb.size(0)\n",
    "            test_mse = test_run / len(test_ds)\n",
    "            hist['test'].append((ep, test_mse))\n",
    "\n",
    "            d_rms = drift_rms_lstm(model, Z_tr.astype(np.float32), H=drift_H)\n",
    "            hist['drift'].append((ep, d_rms))\n",
    "    return model, hist\n",
    "\n",
    "# ---------- Neural ODE (discrete RK4) ----------\n",
    "class ODEFunc(nn.Module):\n",
    "    \"\"\" Vector field f_theta(z) with Tanh MLP. \"\"\"\n",
    "    def __init__(self, dim, width=64, num_hidden=3):\n",
    "        super().__init__()\n",
    "        layers = []\n",
    "        d = dim\n",
    "        for _ in range(num_hidden):\n",
    "            layers += [nn.Linear(d, width), nn.Tanh()]\n",
    "            d = width\n",
    "        layers += [nn.Linear(d, dim)]\n",
    "        self.net = nn.Sequential(*layers)\n",
    "    def forward(self, z):\n",
    "        return self.net(z)\n",
    "\n",
    "def rk4_step(func, z, h):\n",
    "    k1 = func(z)\n",
    "    k2 = func(z + 0.5*h*k1)\n",
    "    k3 = func(z + 0.5*h*k2)\n",
    "    k4 = func(z + h*k3)\n",
    "    return z + (h/6.0)*(k1 + 2*k2 + 2*k3 + k4)\n",
    "\n",
    "\n",
    "def train_neural_ode_with_history(dim, width, num_hidden,\n",
    "                                  train_ds, test_ds,\n",
    "                                  epochs=200, lr=1e-3, batch_size=256, h=dt,\n",
    "                                  eval_every=10, drift_H=800):\n",
    "    model = ODEFunc(dim, width=width, num_hidden=num_hidden).to(device).float()\n",
    "    opt   = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    tl = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "    vl = DataLoader(test_ds,  batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    hist = dict(train=[], test=[], drift=[])\n",
    "    for ep in range(epochs):\n",
    "        model.train()\n",
    "        run = 0.0\n",
    "        for x0, x1 in tl:\n",
    "            x0 = x0.to(device); x1 = x1.to(device)\n",
    "            opt.zero_grad()\n",
    "            x1_hat = rk4_step(model, x0, h)\n",
    "            loss = mse(x1_hat, x1)\n",
    "            loss.backward(); opt.step()\n",
    "            run += loss.item() * x0.size(0)\n",
    "        hist['train'].append(run / len(train_ds))\n",
    "\n",
    "        if (ep % eval_every == 0) or (ep == epochs-1):\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                # test one-step MSE\n",
    "                run = 0.0\n",
    "                for x0, x1 in vl:\n",
    "                    x0 = x0.to(device); x1 = x1.to(device)\n",
    "                    x1_hat = rk4_step(model, x0, h)\n",
    "                    run += mse(x1_hat, x1).item() * x0.size(0)\n",
    "                hist['test'].append((ep, run / len(test_ds)))\n",
    "\n",
    "                # drift RMS on short autoregressive reconstruction\n",
    "                Ztr = Z_tr.astype(np.float32)\n",
    "                H = min(drift_H, len(Ztr))\n",
    "                z_t = torch.from_numpy(Ztr[:1]).to(device)\n",
    "                pred = np.zeros((H, Ztr.shape[1]), dtype=np.float32)\n",
    "                for t in range(H):\n",
    "                    pred[t] = z_t.squeeze(0).cpu().numpy()\n",
    "                    z_t = rk4_step(model, z_t, h)\n",
    "                dH = energy_np(pred, N, lambda_value) - energy_np(pred[:1], N, lambda_value)[0]\n",
    "                hist['drift'].append((ep, float(np.sqrt(np.mean(dH**2)))))\n",
    "    return model, hist\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63fcbc24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_convergence_multi(hists: dict, title=\"Convergence\"):\n",
    "    colors = dict(SympNet='C0', LSTM='C1', NeuralODE='C2')\n",
    "    fig, axs = plt.subplots(3,1, figsize=(9,9), sharex=True)\n",
    "\n",
    "    # Train curves (every epoch)\n",
    "    for name, h in hists.items():\n",
    "        tr = np.array(h['train'])\n",
    "        axs[0].plot(np.arange(len(tr)), tr, lw=1.4, label=name, color=colors.get(name))\n",
    "    axs[0].set_ylabel('Train MSE'); axs[0].set_yscale('log'); axs[0].grid(True); axs[0].legend()\n",
    "\n",
    "    # Test curves (sampled by eval_every)\n",
    "    for name, h in hists.items():\n",
    "        te = np.array(h['test'])\n",
    "        axs[1].plot(te[:,0], te[:,1], 'o-', lw=1.4, ms=4, label=name, color=colors.get(name))\n",
    "    axs[1].set_ylabel('Test MSE'); axs[1].set_yscale('log'); axs[1].grid(True); axs[1].legend()\n",
    "\n",
    "    # Drift curves (sampled by eval_every)\n",
    "    for name, h in hists.items():\n",
    "        ds = np.array(h['drift'])\n",
    "        axs[2].plot(ds[:,0], ds[:,1], 'o-', lw=1.4, ms=4, label=name, color=colors.get(name))\n",
    "    axs[2].set_ylabel('Drift RMS (ΔH)'); axs[2].set_xlabel('Epoch'); axs[2].set_yscale('log'); axs[2].grid(True); axs[2].legend()\n",
    "\n",
    "    fig.suptitle(title)\n",
    "    plt.tight_layout(); plt.show()\n",
    "\n",
    "\n",
    "\n",
    "def plot_metric_vs_params(df, metric='test_mse', title=None):\n",
    "    fig, ax = plt.subplots(figsize=(7.5,5.5))\n",
    "    markers = {'SympNet':'o', 'LSTM':'s', 'NeuralODE':'^'}\n",
    "    for m in sorted(df['model'].unique()):\n",
    "        sub = df[df['model']==m]\n",
    "        ax.scatter(sub['params'], sub[metric], s=50, alpha=0.9,\n",
    "                   label=m, marker=markers.get(m,'o'))\n",
    "    ax.set_xscale('log'); ax.set_yscale('log')\n",
    "    ax.set_xlabel('# parameters (log)'); ax.set_ylabel(metric + ' (log)')\n",
    "    ax.grid(True, which='both', ls='--', alpha=0.3)\n",
    "    if title: ax.set_title(title)\n",
    "    ax.legend()\n",
    "    plt.tight_layout(); plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "517d29bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# SWEEP + METRICS + PLOTS\n",
    "# =========================\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "def n_params(m): return sum(p.numel() for p in m.parameters())\n",
    "def last_metric(hist, key):\n",
    "    # hist['test'] and hist['drift'] are lists of (epoch, value)\n",
    "    return hist[key][-1][1] if (key in hist and len(hist[key])>0) else np.nan\n",
    "\n",
    "# grids\n",
    "# width_mults   = [1, 2, 4, 8]\n",
    "# hidden_layers = [1, 2, 4, 8]   # for SympNet & Neural ODE\n",
    "# width_mults   = [1]\n",
    "# hidden_layers = [1]   # for SympNet & Neural ODE\n",
    "\n",
    "# budgets (tune to your patience)\n",
    "EPOCHS_SYMP = 10\n",
    "EPOCHS_LSTM = 10\n",
    "EPOCHS_ODE  = 200\n",
    "BATCH_SYMP  = 256\n",
    "BATCH_LSTM  = 128\n",
    "LR_SYMP     = 1e-3\n",
    "LR_LSTM     = 1e-3\n",
    "LR_ODE      = 1e-3\n",
    "EVAL_EVERY  = 10\n",
    "DRIFT_H     = 800\n",
    "\n",
    "results = []\n",
    "\n",
    "# ---- SympNet sweep ----\n",
    "for L in hidden_layers:\n",
    "    for mult in width_mults:\n",
    "        W = mult * nf\n",
    "        model, hist = train_sympnet_with_history(\n",
    "            dim=nf, width=W, num_hidden=L,\n",
    "            train_ds=train_ds_symp, test_ds=test_ds_symp,\n",
    "            epochs=EPOCHS_SYMP, lr=LR_SYMP, batch_size=BATCH_SYMP, h=float(dt),\n",
    "            eval_every=EVAL_EVERY, drift_H=DRIFT_H\n",
    "        )\n",
    "        row = dict(\n",
    "            model='SympNet', layers=L, width=W, params=n_params(model),\n",
    "            train_mse=hist['train'][-1],\n",
    "            test_mse=last_metric(hist,'test'),\n",
    "            drift_rms=last_metric(hist,'drift'),\n",
    "            drift_max=np.nan, seconds=np.nan\n",
    "        )\n",
    "        results.append(row)\n",
    "        print(f\"[SympNet] L={L} W={W} | train={row['train_mse']:.3e}  test={row['test_mse']:.3e}  drift_rms={row['drift_rms']:.3e}  params={row['params']}\")\n",
    "\n",
    "# ---- LSTM sweep (hidden size only; num_layers=1) ----\n",
    "for mult in width_mults:\n",
    "    H = mult * nf\n",
    "    model, hist = train_lstm_with_history(\n",
    "        input_dim=nf, hidden_dim=H,\n",
    "        train_ds=train_ds_lstm, test_ds=test_ds_lstm,\n",
    "        epochs=EPOCHS_LSTM, lr=LR_LSTM, batch_size=BATCH_LSTM,\n",
    "        eval_every=EVAL_EVERY, drift_H=DRIFT_H\n",
    "    )\n",
    "    row = dict(\n",
    "        model='LSTM', layers=1, width=H, params=n_params(model),\n",
    "        train_mse=hist['train'][-1],\n",
    "        test_mse=last_metric(hist,'test'),\n",
    "        drift_rms=last_metric(hist,'drift'),\n",
    "        drift_max=np.nan, seconds=np.nan\n",
    "    )\n",
    "    results.append(row)\n",
    "    print(f\"[LSTM]    H={H} | train={row['train_mse']:.3e}  test={row['test_mse']:.3e}  drift_rms={row['drift_rms']:.3e}  params={row['params']}\")\n",
    "\n",
    "# ---- Neural ODE sweep ----\n",
    "for L in hidden_layers:\n",
    "    for mult in width_mults:\n",
    "        W = mult * nf\n",
    "        model, hist = train_neural_ode_with_history(\n",
    "            dim=nf, width=W, num_hidden=L,\n",
    "            train_ds=train_ds_symp, test_ds=test_ds_symp,\n",
    "            epochs=EPOCHS_ODE, lr=LR_ODE, batch_size=BATCH_SYMP, h=float(dt),\n",
    "            eval_every=EVAL_EVERY, drift_H=DRIFT_H\n",
    "        )\n",
    "        # Convert history -> metrics for the sweep table\n",
    "        metrics = {\n",
    "            'train_mse': float(hist['train'][-1]),\n",
    "            'test_mse':  float(last_metric(hist, 'test')),\n",
    "            'drift_rms': float(last_metric(hist, 'drift')),\n",
    "            'drift_max': np.nan,            # not tracked in *_with_history (optional to add)\n",
    "            'params':    n_params(model),\n",
    "            'seconds':   np.nan             # add timing if you want\n",
    "        }\n",
    "        row = dict(model='NeuralODE', layers=L, width=W, **metrics)\n",
    "        results.append(row)\n",
    "        print(f\"[NeuralODE] L={L} W={W} | \"\n",
    "              f\"train={metrics['train_mse']:.3e}  \"\n",
    "              f\"test={metrics['test_mse']:.3e}  \"\n",
    "              f\"drift_rms={metrics['drift_rms']:.3e}  \"\n",
    "              f\"params={metrics['params']}\")\n",
    "\n",
    "\n",
    "plot_metric_vs_params(df_sweep, metric='test_mse',  title='Test MSE vs Parameters')\n",
    "plot_metric_vs_params(df_sweep, metric='drift_rms', title='Energy Drift (RMS ΔH) vs Parameters')\n",
    "best_rows = (df_sweep\n",
    "             .sort_values('test_mse')\n",
    "             .groupby('model', as_index=False)\n",
    "             .first())\n",
    "\n",
    "# Training budgets for the convergence runs (can reuse your sweep budgets)\n",
    "EPOCHS_CONV_SYMP = EPOCHS_SYMP\n",
    "EPOCHS_CONV_LSTM = EPOCHS_LSTM\n",
    "EPOCHS_CONV_ODE  = EPOCHS_ODE\n",
    "\n",
    "hists = {}\n",
    "\n",
    "for _, r in best_rows.iterrows():\n",
    "    if r['model'] == 'SympNet':\n",
    "        L, W = int(r['layers']), int(r['width'])\n",
    "        symp_best_model, symp_best_hist = train_sympnet_with_history(\n",
    "            dim=nf, width=W, num_hidden=L,\n",
    "            train_ds=train_ds_symp, test_ds=test_ds_symp,\n",
    "            epochs=EPOCHS_CONV_SYMP, lr=LR_SYMP, batch_size=BATCH_SYMP, h=float(dt),\n",
    "            eval_every=EVAL_EVERY, drift_H=DRIFT_H\n",
    "        )\n",
    "        hists['SympNet'] = symp_best_hist\n",
    "\n",
    "    elif r['model'] == 'LSTM':\n",
    "        Hsz = int(r['width'])  # we stored hidden size in 'width' for LSTM\n",
    "        lstm_best_model, lstm_best_hist = train_lstm_with_history(\n",
    "            input_dim=nf, hidden_dim=Hsz,\n",
    "            train_ds=train_ds_lstm, test_ds=test_ds_lstm,\n",
    "            epochs=EPOCHS_CONV_LSTM, lr=LR_LSTM, batch_size=BATCH_LSTM,\n",
    "            eval_every=EVAL_EVERY, drift_H=DRIFT_H\n",
    "        )\n",
    "        hists['LSTM'] = lstm_best_hist\n",
    "\n",
    "    elif r['model'] == 'NeuralODE':\n",
    "        L, W = int(r['layers']), int(r['width'])\n",
    "        ode_best_model, ode_best_hist = train_neural_ode_with_history(\n",
    "            dim=nf, width=W, num_hidden=L,\n",
    "            train_ds=train_ds_symp, test_ds=test_ds_symp,\n",
    "            epochs=EPOCHS_CONV_ODE, lr=LR_ODE, batch_size=BATCH_SYMP, h=float(dt),\n",
    "            eval_every=EVAL_EVERY, drift_H=DRIFT_H\n",
    "        )\n",
    "        hists['NeuralODE'] = ode_best_hist\n",
    "\n",
    "# 4) Plot all three on one convergence figure\n",
    "plot_convergence_multi(\n",
    "    hists,\n",
    "    title=\"Convergence (best configs by sweep)\"\n",
    ")\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
